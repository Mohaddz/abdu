{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Text Classification - Active Learning Pipelines\n",
    "\n",
    "This notebook demonstrates two active learning approaches for Arabic text classification:\n",
    "1. **Uncertainty Sampling Pipeline**: Uses SBERT embeddings with a single classifier\n",
    "2. **Committee-Based Sampling Pipeline**: Uses SBERT embeddings with multiple classifiers\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.getcwd()) if 'notebooks' in os.getcwd() else os.getcwd()\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.embeddings import SBERTEmbedder\n",
    "from pipelines.uncertainty_sampling import UncertaintySamplingPipeline\n",
    "from pipelines.committee_sampling import CommitteeSamplingPipeline\n",
    "\n",
    "print(f\"Using device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data\n",
    "\n",
    "Let's create sample Arabic text data for demonstration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data(output_path: str = \"data/sample_arabic_data.csv\", n_samples: int = 500):\n",
    "    \"\"\"Create sample Arabic text data for testing\"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    security_texts = [\n",
    "        \"تسريب البيانات الشخصية للمستخدمين\",\n",
    "        \"هجمات القرصنة الإلكترونية على البنوك\",\n",
    "        \"اختراق أنظمة الحماية الرقمية\",\n",
    "        \"برمجيات خبيثة تهدد الشبكات\",\n",
    "        \"فيروسات الحاسوب والبرمجيات الضارة\",\n",
    "        \"سرقة كلمات المرور والحسابات\",\n",
    "        \"أمان المعلومات والحماية الرقمية\",\n",
    "        \"تشفير البيانات الحساسة\",\n",
    "        \"حماية الخصوصية على الإنترنت\",\n",
    "        \"أمان الشبكات والخوادم\"\n",
    "    ]\n",
    "    \n",
    "    non_security_texts = [\n",
    "        \"الطقس اليوم مشمس وجميل\",\n",
    "        \"وصفة الطبخ التقليدية العربية\",\n",
    "        \"أخبار الرياضة والمباريات\",\n",
    "        \"السياحة والسفر إلى البلدان العربية\",\n",
    "        \"التعليم والثقافة في المجتمع\",\n",
    "        \"الفنون والموسيقى العربية\",\n",
    "        \"الأدب والشعر الكلاسيكي\",\n",
    "        \"التجارة والاقتصاد المحلي\",\n",
    "        \"الصحة والطب التقليدي\",\n",
    "        \"التكنولوجيا والابتكار\"\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for i in range(n_samples):\n",
    "        if i % 2 == 0:\n",
    "            text = np.random.choice(security_texts)\n",
    "            label = 1  # Security-related\n",
    "        else:\n",
    "            text = np.random.choice(non_security_texts)\n",
    "            label = 0  # Non-security\n",
    "        \n",
    "        data.append({\n",
    "            'text': f\"{text} - عينة رقم {i+1}\",\n",
    "            'label': label\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    print(f\"Sample data created at: {output_path}\")\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    print(f\"Label distribution:\\n{df['label'].value_counts()}\")\n",
    "    return output_path\n",
    "\n",
    "# Create sample data\n",
    "data_path = create_sample_data(f\"{project_root}/data/sample_arabic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader and embedder\n",
    "data_loader = DataLoader(data_path)\n",
    "embedder = SBERTEmbedder()\n",
    "\n",
    "# Get initial split: small labeled set, large unlabeled set\n",
    "labeled_texts, labeled_labels, unlabeled_texts, unlabeled_labels = data_loader.get_initial_split(\n",
    "    initial_labeled_size=50, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Initial labeled pool size: {len(labeled_texts)}\")\n",
    "print(f\"Initial unlabeled pool size: {len(unlabeled_texts)}\")\n",
    "print(f\"Label distribution in labeled set: {np.unique(labeled_labels, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1: Uncertainty Sampling\n",
    "\n",
    "This pipeline uses a single classifier with uncertainty sampling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Uncertainty Sampling Pipeline\n",
    "uncertainty_pipeline = UncertaintySamplingPipeline(\n",
    "    embedder=embedder, \n",
    "    classifier_type='logistic',  # Can be 'logistic' or 'svm'\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the pools\n",
    "uncertainty_pipeline.initialize_pools(labeled_texts, labeled_labels, unlabeled_texts)\n",
    "\n",
    "print(\"Uncertainty Sampling Pipeline initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Active Learning Iterations - Uncertainty Sampling\n",
    "print(\"Running Uncertainty Sampling Pipeline...\\n\")\n",
    "\n",
    "uncertainty_results = []\n",
    "\n",
    "for iteration in range(2):  # Run 2 iterations\n",
    "    print(f\"--- Iteration {iteration + 1} ---\")\n",
    "    \n",
    "    # Run one active learning iteration\n",
    "    results = uncertainty_pipeline.run_active_learning_iteration(\n",
    "        n_samples=10, \n",
    "        strategy='least_confident'  # Options: 'least_confident', 'margin', 'entropy'\n",
    "    )\n",
    "    \n",
    "    print(f\"Pool sizes: Labeled={results['pool_sizes']['labeled']}, Unlabeled={results['pool_sizes']['unlabeled']}\")\n",
    "    print(f\"Selected {len(results['selected_texts'])} samples with {results['strategy']} strategy\")\n",
    "    \n",
    "    # Show top 3 most uncertain samples\n",
    "    print(\"\\nTop 3 most uncertain samples:\")\n",
    "    for i, (text, uncertainty) in enumerate(zip(results['selected_texts'][-3:], results['uncertainties'][-3:])):\n",
    "        print(f\"{i+1}. Uncertainty: {uncertainty:.4f}\")\n",
    "        print(f\"   Text: {text[:100]}...\\n\")\n",
    "    \n",
    "    # Simulate labeling process (in real scenario, human would label these)\n",
    "    simulated_labels = []\n",
    "    for text in results['selected_texts']:\n",
    "        # Simple heuristic for simulation: if text contains security keywords, label as 1\n",
    "        if any(keyword in text for keyword in ['أمان', 'حماية', 'تسريب', 'اختراق', 'فيروس']):\n",
    "            simulated_labels.append(1)\n",
    "        else:\n",
    "            simulated_labels.append(0)\n",
    "    \n",
    "    # Add newly labeled samples to the pipeline\n",
    "    uncertainty_pipeline.add_labeled_samples(\n",
    "        results['selected_texts'], \n",
    "        simulated_labels, \n",
    "        results['selected_indices']\n",
    "    )\n",
    "    \n",
    "    uncertainty_results.append(results)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "print(\"Uncertainty Sampling Pipeline completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 2: Committee-Based Sampling\n",
    "\n",
    "This pipeline uses multiple classifiers and measures their disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Committee Sampling Pipeline\n",
    "committee_pipeline = CommitteeSamplingPipeline(\n",
    "    embedder=embedder,\n",
    "    use_gpu_lightgbm=True,  # Use GPU-accelerated LightGBM if available\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the pools (using fresh copies)\n",
    "committee_pipeline.initialize_pools(labeled_texts, labeled_labels, unlabeled_texts)\n",
    "\n",
    "print(\"Committee-Based Sampling Pipeline initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Active Learning Iterations - Committee Sampling\n",
    "print(\"Running Committee-Based Sampling Pipeline...\\n\")\n",
    "\n",
    "committee_results = []\n",
    "\n",
    "for iteration in range(2):  # Run 2 iterations\n",
    "    print(f\"--- Iteration {iteration + 1} ---\")\n",
    "    \n",
    "    # Run one active learning iteration\n",
    "    results = committee_pipeline.run_active_learning_iteration(\n",
    "        n_samples=10,\n",
    "        strategy='vote_entropy'  # Options: 'vote_entropy', 'disagreement'\n",
    "    )\n",
    "    \n",
    "    print(f\"Pool sizes: Labeled={results['pool_sizes']['labeled']}, Unlabeled={results['pool_sizes']['unlabeled']}\")\n",
    "    \n",
    "    # Show committee performance\n",
    "    print(\"\\nCommittee Member Accuracies:\")\n",
    "    for classifier_name, accuracy in results['committee_accuracies'].items():\n",
    "        print(f\"  {classifier_name}: {accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"\\nSelected {len(results['selected_texts'])} samples with {results['strategy']} strategy\")\n",
    "    \n",
    "    # Show top 3 most disagreed samples\n",
    "    print(\"\\nTop 3 most disagreed samples:\")\n",
    "    for i, (text, score) in enumerate(zip(results['selected_texts'][-3:], results['scores'][-3:])):\n",
    "        print(f\"{i+1}. {results['strategy'].title()}: {score:.4f}\")\n",
    "        print(f\"   Text: {text[:100]}...\\n\")\n",
    "    \n",
    "    # Simulate labeling process\n",
    "    simulated_labels = []\n",
    "    for text in results['selected_texts']:\n",
    "        if any(keyword in text for keyword in ['أمان', 'حماية', 'تسريب', 'اختراق', 'فيروس']):\n",
    "            simulated_labels.append(1)\n",
    "        else:\n",
    "            simulated_labels.append(0)\n",
    "    \n",
    "    # Add newly labeled samples to the pipeline\n",
    "    committee_pipeline.add_labeled_samples(\n",
    "        results['selected_texts'], \n",
    "        simulated_labels, \n",
    "        results['selected_indices']\n",
    "    )\n",
    "    \n",
    "    committee_results.append(results)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "print(\"Committee-Based Sampling Pipeline completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of both pipelines\n",
    "print(\"ACTIVE LEARNING PIPELINES SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. UNCERTAINTY SAMPLING PIPELINE:\")\n",
    "print(f\"   - Final labeled pool size: {uncertainty_pipeline.get_pool_sizes()['labeled']}\")\n",
    "print(f\"   - Final unlabeled pool size: {uncertainty_pipeline.get_pool_sizes()['unlabeled']}\")\n",
    "print(f\"   - Classifier type: {uncertainty_pipeline.classifier_type}\")\n",
    "print(f\"   - Sampling strategy: least_confident\")\n",
    "\n",
    "print(\"\\n2. COMMITTEE-BASED SAMPLING PIPELINE:\")\n",
    "print(f\"   - Final labeled pool size: {committee_pipeline.get_pool_sizes()['labeled']}\")\n",
    "print(f\"   - Final unlabeled pool size: {committee_pipeline.get_pool_sizes()['unlabeled']}\")\n",
    "print(f\"   - Committee size: {len(committee_pipeline.committee)} classifiers\")\n",
    "print(f\"   - Committee members: {[type(c).__name__ for c in committee_pipeline.committee]}\")\n",
    "print(f\"   - Sampling strategy: vote_entropy\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Both pipelines completed successfully!\")\n",
    "print(\"You can now use your own Arabic CSV data by updating the data_path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Your Own Data\n",
    "\n",
    "To use your own Arabic text data:\n",
    "\n",
    "1. **Prepare your CSV file** with columns:\n",
    "   - `text`: Arabic text content\n",
    "   - `label`: Binary labels (0 for non-security, 1 for security)\n",
    "\n",
    "2. **Update the data path**:\n",
    "   ```python\n",
    "   data_path = \"path/to/your/arabic_data.csv\"\n",
    "   data_loader = DataLoader(data_path)\n",
    "   ```\n",
    "\n",
    "3. **Customize the pipelines**:\n",
    "   - Adjust `initial_labeled_size` based on your budget\n",
    "   - Choose different sampling strategies\n",
    "   - Modify the number of iterations\n",
    "   - Change the number of samples per iteration\n",
    "\n",
    "4. **Replace simulated labeling** with real human annotation:\n",
    "   ```python\n",
    "   # Instead of simulated_labels, get real labels from annotators\n",
    "   real_labels = get_human_annotations(results['selected_texts'])\n",
    "   pipeline.add_labeled_samples(results['selected_texts'], real_labels, results['selected_indices'])\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}